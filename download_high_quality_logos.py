import os
import csv
import requests
from urllib.parse import urlparse
from PIL import Image
import io
import re  # ‡§∞‡•á‡§ó‡•Å‡§≤‡§∞ ‡§è‡§ï‡•ç‡§∏‡§™‡•ç‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è

def get_domain(url):
    if not url:
        return None
    
    cleaned_url = re.sub(r'[\[\]"\']', '', url.strip())
    cleaned_url = cleaned_url.split()[0]
    
    try:
        parsed = urlparse(cleaned_url)
        domain = parsed.netloc.lower().replace("www.", "")
        return domain if domain else None
    except:
        return None

def download_high_quality_png(domain, product_title, category, output_dir):
    if not domain:
        return False
    
    if product_title:
        clean_title = product_title.lower().strip().replace(" ", "-")
        filename_base = f"{clean_title}-{category.replace(' ', '-')}"
    else:
        filename_base = domain.replace(".", "-")
    
    filename = f"{filename_base}.png"
    path = os.path.join(output_dir, filename)

    api_list = [
        f"https://icons.duckduckgo.com/ip3/{domain}.ico",
        f"https://api.faviconkit.com/{domain}/256",
        f"https://s2.googleusercontent.com/s2/favicons?domain={domain}&sz=256",
        f"https://logo.clearbit.com/{domain}?size=256"
    ]

    for api_url in api_list:
        try:
            print(f"  ‡§ü‡•ç‡§∞‡§æ‡§Ø ‡§ï‡§∞ ‡§∞‡§π‡§æ: {api_url.split('//')[1].split('/')[0]}")
            response = requests.get(api_url, timeout=10, stream=True)
            if response.status_code == 200:
                img_data = io.BytesIO(response.content)
                img = Image.open(img_data)
                
                if img.format == 'ICO':
                    img = img.resize((256, 256), Image.LANCZOS)
                
                img = img.convert("RGBA")
                img.save(path, "PNG", quality=100, optimize=False)
                print(f"‚úì ‡§∏‡•á‡§µ ‡§π‡•ã ‡§ó‡§Ø‡§æ: {filename}")
                return True
                
        except Exception as e:
            print(f"  ‡§´‡•á‡§≤: {api_url.split('//')[1].split('/')[0]} ‚Üí {str(e)}")

    print(f"‚úó ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ: {domain} ({product_title})")
    return False


# ================= MAIN PROGRAM =================

csv_file_path = input(
    "CSV ‡§´‡§æ‡§á‡§≤ ‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§™‡§æ‡§• ‡§°‡§æ‡§≤‡•ã (‡§â‡§¶‡§æ‡§π‡§∞‡§£: C:/Users/You/Desktop/data.csv): "
).strip()

if not os.path.exists(csv_file_path):
    print("‡§´‡§æ‡§á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä! ‡§∏‡§π‡•Ä ‡§™‡§æ‡§• ‡§ö‡•á‡§ï ‡§ï‡§∞‡•ã")
    exit()

# üîß CHANGE 1: CSV ‡§µ‡§æ‡§≤‡•á folder ‡§ï‡§æ path
base_dir = os.path.dirname(csv_file_path)

# üîß CHANGE 2: ‡§â‡§∏‡•Ä folder ‡§Æ‡•á‡§Ç 'logos' ‡§®‡§æ‡§Æ ‡§ï‡§æ folder ‡§¨‡§®‡§æ‡§ì
logos_dir = os.path.join(base_dir, "logos")
os.makedirs(logos_dir, exist_ok=True)

print(f"‡§á‡§Æ‡•á‡§ú‡•á‡§∏ ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•á‡§µ ‡§π‡•ã‡§Ç‡§ó‡•Ä: {logos_dir}")

success_count = 0
fail_count = 0

with open(csv_file_path, 'r', encoding='utf-8', newline='') as csvfile:
    reader = csv.DictReader(csvfile)
    
    for row in reader:
        url = row.get('product.metafields.custom.custom', '').strip()
        title = row.get('Title', '').strip()
        category = row.get('Product Category', 'Unknown').strip()
        
        domain = get_domain(url)
        
        if not domain:
            print(f"Invalid URL skipped: {url}")
            continue
            
        print(f"\nProcessing: {domain} ‚Üí {title}")
        
        # üîß CHANGE 3: output_dir ‡§ï‡•Ä ‡§ú‡§ó‡§π logos_dir
        if download_high_quality_png(domain, title, category, logos_dir):
            success_count += 1
        else:
            fail_count += 1

print("\n" + "="*70)
print(f"‡§∏‡§Æ‡§æ‡§™‡•ç‡§§! ‡§ï‡•Å‡§≤ domains ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏: {success_count + fail_count}")
print(f"‡§∏‡§´‡§≤ ‡§π‡§æ‡§à ‡§ï‡•ç‡§µ‡§æ‡§≤‡§ø‡§ü‡•Ä PNG ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°: {success_count}")
print(f"‡§´‡•á‡§≤/‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•á: {fail_count}")
print(f"‡§∏‡§≠‡•Ä PNG ‡§´‡§æ‡§á‡§≤‡•á‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•á‡§µ: {logos_dir}")
print("="*70)
